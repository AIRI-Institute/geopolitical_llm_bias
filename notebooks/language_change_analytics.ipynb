{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a98570ff-8b90-43a1-92ee-4793fdbb0aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "efdf86e8-47d5-494d-a0c1-230540a72982",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_language = f'ch' #select current language\n",
    "CHINESE_PATRIOTISM = False #set True if use CHINESE_PATRIOTISM\n",
    "PATH_TO_CSV = f\"Historic_Data_patriot_{current_language}.csv\" if CHINESE_PATRIOTISM else f\"Historic_Data_{current_language}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d770d017-a702-4822-9233-7ab1c72b6d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(PATH_TO_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ca4d33d4-70d8-4fba-b939-991678f3cbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "refuse_answers = [\n",
    "    'GigaChat-Max_answers_refuse_chinese_patriotism',\n",
    "    'Qwen2.5_72B_answers_refuse_chinese_patriotism',\n",
    "    'llama-4-maverick_answers_refuse_chinese_patriotism',\n",
    "    'gpt-4o-mini_answers_refuse_chinese_patriotism',\n",
    "] if CHINESE_PATRIOTISM else [\n",
    "    'GigaChat-Max_answers_refuse',\n",
    "    'Qwen2.5_72B_answers_refuse',\n",
    "    'llama-4-maverick_answers_refuse',\n",
    "    'gpt-4o-mini_answers_refuse',\n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "be16bf31-0ef2-4ea8-965b-be2e3e4e9429",
   "metadata": {},
   "outputs": [],
   "source": [
    "debias_prompt_refuse_answers = [\n",
    "    'GigaChat-Max_answers_debias_prompt_refuse_chinese_patriotism',\n",
    "    'Qwen2.5_72B_answers_debias_prompt_refuse_chinese_patriotism',\n",
    "    'llama-4-maverick_answers_debias_prompt_refuse_chinese_patriotism',\n",
    "    'gpt-4o-mini_answers_debias_prompt_refuse_chinese_patriotism',\n",
    "] if CHINESE_PATRIOTISM else [\n",
    "    'GigaChat-Max_answers_debias_prompt_refuse',\n",
    "    'Qwen2.5_72B_answers_debias_prompt_refuse',\n",
    "    'llama-4-maverick_answers_debias_prompt_refuse',\n",
    "    'gpt-4o-mini_answers_debias_prompt_refuse',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "81c840a9-d58e-4a8f-b239-0a1ac86bb23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "refuse_mention_participant_answers = [\n",
    "    'GigaChat-Max_answers_refuse_chinese_patriotism_mention_participant',\n",
    "    'Qwen2.5_72B_answers_refuse_chinese_patriotism_mention_participant',\n",
    "    'llama-4-maverick_answers_refuse_chinese_patriotism_mention_participant',\n",
    "    'gpt-4o-mini_answers_refuse_chinese_patriotism_mention_participant',\n",
    "] if CHINESE_PATRIOTISM else [\n",
    "    'GigaChat-Max_answers_refuse_mention_participant',\n",
    "    'Qwen2.5_72B_answers_refuse_mention_participant',\n",
    "    'llama-4-maverick_answers_refuse_mention_participant',\n",
    "    'gpt-4o-mini_answers_refuse_mention_participant',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d3dff676-06d5-4079-9c9e-64c1d3d552b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "refuse_swap_mention_participant_answers = [\n",
    "    'GigaChat-Max_answers_refuse_chinese_patriotism_swap_mention_participant',\n",
    "    'Qwen2.5_72B_answers_refuse_chinese_patriotism_swap_mention_participant',\n",
    "    'llama-4-maverick_answers_refuse_chinese_patriotism_swap_mention_participant',\n",
    "    'gpt-4o-mini_answers_refuse_chinese_patriotism_swap_mention_participant',\n",
    "] if CHINESE_PATRIOTISM else [\n",
    "    'GigaChat-Max_answers_refuse_swap_mention_participant',\n",
    "    'Qwen2.5_72B_answers_refuse_swap_mention_participant',\n",
    "    'llama-4-maverick_answers_refuse_swap_mention_participant',\n",
    "    'gpt-4o-mini_answers_refuse_swap_mention_participant',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "95c61529-5f88-4e19-966d-353c3f575d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"('UK', 'China')\", \"('UK', 'USA')\", \"('UK', 'USSR')\",\n",
       "       \"('USA', 'China')\", \"('USSR', 'China')\", \"('USSR', 'USA')\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries = df['countries']\n",
    "np.unique(countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "5434a081-cc75-44f0-8865-c991f1a918ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_countries =  \"('USSR', 'USA')\" #select countries pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "c1a0abb2-8c41-4d13-8a45-981258e70edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = {\n",
    "    'GigaChat-Max':[],\n",
    "    'Qwen2.5 72B':[],\n",
    "    'Llama-4-Mav.':[],\n",
    "    'gpt-4o-mini':[],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0a767e-aac2-426a-b15b-198e11d9fe0e",
   "metadata": {},
   "source": [
    "## refuse_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "dc751e97-ad5d-4b62-be5c-93a12a470696",
   "metadata": {},
   "outputs": [],
   "source": [
    "refuse_df = df[df['countries'] == curr_countries][refuse_answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "44c1563d-c418-48c0-bed6-1893dc411f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_p_d = {k:[] for k in list(refuse_df.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "1e605a5e-c2ba-4a92-a853-e02de9c30ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(refuse_df)):\n",
    "    for r_n in refuse_answers:\n",
    "        curr_dict = eval(refuse_df.iloc[[i]][r_n].values[0])\n",
    "        c_a_a = []\n",
    "        for j in range(len(curr_dict)):\n",
    "            c_p = eval(curr_dict[j])['correct_position']\n",
    "            c_a_a.append(c_p)\n",
    "            \n",
    "        counter = Counter(c_a_a)\n",
    "        most_common = counter.most_common(1)[0][0]\n",
    "        c_p_d[r_n].append(most_common)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "90a46adb-ab08-419b-8641-12a4a94f4edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GigaChat-Max_answers_refuse:\n",
      "  Ответ 1: 7 (28.00%)\n",
      "  Ответ 2: 14 (56.00%)\n",
      "  Ответ 3: 1 (4.00%)\n",
      "  Ответ 4: 3 (12.00%)\n",
      "\n",
      "Qwen2.5_72B_answers_refuse:\n",
      "  Ответ 1: 8 (32.00%)\n",
      "  Ответ 2: 10 (40.00%)\n",
      "  Ответ 3: 1 (4.00%)\n",
      "  Ответ 4: 6 (24.00%)\n",
      "\n",
      "llama-4-maverick_answers_refuse:\n",
      "  Ответ 1: 1 (4.00%)\n",
      "  Ответ 2: 4 (16.00%)\n",
      "  Ответ 3: 2 (8.00%)\n",
      "  Ответ 4: 18 (72.00%)\n",
      "\n",
      "gpt-4o-mini_answers_refuse:\n",
      "  Ответ 1: 4 (16.00%)\n",
      "  Ответ 2: 20 (80.00%)\n",
      "  Ответ 3: 1 (4.00%)\n",
      "  Ответ 4: 0 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "for model, responses in c_p_d.items():\n",
    "    counter = Counter(responses)\n",
    "    total_answers = len(refuse_df)\n",
    "    print(f\"\\n{model}:\")\n",
    "    for i in range(1, 5):\n",
    "        count = counter.get(i, 0)\n",
    "        percentage = (count / total_answers) * 100\n",
    "        print(f\"  Ответ {i}: {count} ({percentage:.2f}%)\")\n",
    "        if f\"GigaChat\" in model:\n",
    "            model_names['GigaChat-Max'].append({i: percentage})\n",
    "        if f\"Qwen\" in model:\n",
    "            model_names['Qwen2.5 72B'].append({i: percentage})\n",
    "        if f\"llama\" in model:\n",
    "            model_names['Llama-4-Mav.'].append({i: percentage})\n",
    "        if f\"gpt\" in model:\n",
    "            model_names['gpt-4o-mini'].append({i: percentage})\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba03f01-d2cf-47a9-82ee-c478d8ccf33f",
   "metadata": {},
   "source": [
    "## debias_prompt_refuse_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ef365108-88a2-4f84-a1b4-f558020255ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_df = df[df['countries'] == curr_countries][debias_prompt_refuse_answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1626f161-3b63-40f2-afb6-138980ea8acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GigaChat-Max_answers_debias_prompt_refuse',\n",
       " 'Qwen2.5_72B_answers_debias_prompt_refuse',\n",
       " 'llama-4-maverick_answers_debias_prompt_refuse',\n",
       " 'gpt-4o-mini_answers_debias_prompt_refuse']"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(curr_df.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "fcea8dbe-2a54-4039-81fa-aeec51beb6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_p_d = {k:[] for k in list(curr_df.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "403f73a9-7764-45f4-9a56-8ee6f6d34a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(curr_df)):\n",
    "    for r_n in debias_prompt_refuse_answers:\n",
    "        curr_dict = eval(curr_df.iloc[[i]][r_n].values[0])\n",
    "        c_a_a = []\n",
    "        for j in range(len(curr_dict)):\n",
    "            c_p = eval(curr_dict[j])['correct_position']\n",
    "            c_a_a.append(c_p)\n",
    "            \n",
    "        counter = Counter(c_a_a)\n",
    "        most_common = counter.most_common(1)[0][0]\n",
    "        c_p_d[r_n].append(most_common)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8ec71fe3-b4f1-4dd3-8f8b-5abdaf3ea40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GigaChat-Max_answers_debias_prompt_refuse:\n",
      "  Ответ 1: 7 (28.00%)\n",
      "  Ответ 2: 14 (56.00%)\n",
      "  Ответ 3: 2 (8.00%)\n",
      "  Ответ 4: 2 (8.00%)\n",
      "\n",
      "Qwen2.5_72B_answers_debias_prompt_refuse:\n",
      "  Ответ 1: 8 (32.00%)\n",
      "  Ответ 2: 9 (36.00%)\n",
      "  Ответ 3: 1 (4.00%)\n",
      "  Ответ 4: 7 (28.00%)\n",
      "\n",
      "llama-4-maverick_answers_debias_prompt_refuse:\n",
      "  Ответ 1: 1 (4.00%)\n",
      "  Ответ 2: 5 (20.00%)\n",
      "  Ответ 3: 2 (8.00%)\n",
      "  Ответ 4: 17 (68.00%)\n",
      "\n",
      "gpt-4o-mini_answers_debias_prompt_refuse:\n",
      "  Ответ 1: 3 (12.00%)\n",
      "  Ответ 2: 21 (84.00%)\n",
      "  Ответ 3: 1 (4.00%)\n",
      "  Ответ 4: 0 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "for model, responses in c_p_d.items():\n",
    "    counter = Counter(responses)\n",
    "    total_answers = len(refuse_df)\n",
    "    print(f\"\\n{model}:\")\n",
    "    for i in range(1, 5):\n",
    "        count = counter.get(i, 0)\n",
    "        percentage = (count / total_answers) * 100\n",
    "        print(f\"  Ответ {i}: {count} ({percentage:.2f}%)\")\n",
    "        if f\"GigaChat\" in model:\n",
    "            model_names['GigaChat-Max'].append({i: percentage})\n",
    "        if f\"Qwen\" in model:\n",
    "            model_names['Qwen2.5 72B'].append({i: percentage})\n",
    "        if f\"llama\" in model:\n",
    "            model_names['Llama-4-Mav.'].append({i: percentage})\n",
    "        if f\"gpt\" in model:\n",
    "            model_names['gpt-4o-mini'].append({i: percentage})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce3b633-af87-4f3e-9440-c379e376ae31",
   "metadata": {},
   "source": [
    "## refuse_mention_participant_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ace9d0b6-37b0-4880-8c71-6a653c9aa61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_df = df[df['countries'] == curr_countries][refuse_mention_participant_answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b57c06f7-eade-4476-9306-533208537e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GigaChat-Max_answers_refuse_mention_participant',\n",
       " 'Qwen2.5_72B_answers_refuse_mention_participant',\n",
       " 'llama-4-maverick_answers_refuse_mention_participant',\n",
       " 'gpt-4o-mini_answers_refuse_mention_participant']"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(curr_df.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "bfa7d655-a166-4e53-95fd-2b29de2902bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_p_d = {k:[] for k in list(curr_df.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "05d520c9-3eb3-47df-b0d6-958e356dc800",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(curr_df)):\n",
    "    for r_n in refuse_mention_participant_answers:\n",
    "        curr_dict = eval(curr_df.iloc[[i]][r_n].values[0])\n",
    "        c_a_a = []\n",
    "        for j in range(len(curr_dict)):\n",
    "            c_p = eval(curr_dict[j])['correct_position']\n",
    "            c_a_a.append(c_p)\n",
    "            \n",
    "        counter = Counter(c_a_a)\n",
    "        most_common = counter.most_common(1)[0][0]\n",
    "        c_p_d[r_n].append(most_common)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b9668b08-d309-4a63-bdf5-e52e8eeb31f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GigaChat-Max_answers_refuse_mention_participant:\n",
      "  Ответ 1: 3 (12.00%)\n",
      "  Ответ 2: 7 (28.00%)\n",
      "  Ответ 3: 0 (0.00%)\n",
      "  Ответ 4: 15 (60.00%)\n",
      "\n",
      "Qwen2.5_72B_answers_refuse_mention_participant:\n",
      "  Ответ 1: 6 (24.00%)\n",
      "  Ответ 2: 7 (28.00%)\n",
      "  Ответ 3: 1 (4.00%)\n",
      "  Ответ 4: 11 (44.00%)\n",
      "\n",
      "llama-4-maverick_answers_refuse_mention_participant:\n",
      "  Ответ 1: 2 (8.00%)\n",
      "  Ответ 2: 4 (16.00%)\n",
      "  Ответ 3: 3 (12.00%)\n",
      "  Ответ 4: 16 (64.00%)\n",
      "\n",
      "gpt-4o-mini_answers_refuse_mention_participant:\n",
      "  Ответ 1: 3 (12.00%)\n",
      "  Ответ 2: 18 (72.00%)\n",
      "  Ответ 3: 4 (16.00%)\n",
      "  Ответ 4: 0 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "for model, responses in c_p_d.items():\n",
    "    counter = Counter(responses)\n",
    "    total_answers = len(refuse_df)\n",
    "    print(f\"\\n{model}:\")\n",
    "    for i in range(1, 5):\n",
    "        count = counter.get(i, 0)\n",
    "        percentage = (count / total_answers) * 100\n",
    "        print(f\"  Ответ {i}: {count} ({percentage:.2f}%)\")\n",
    "\n",
    "        if f\"GigaChat\" in model:\n",
    "            model_names['GigaChat-Max'].append({i: percentage})\n",
    "        if f\"Qwen\" in model:\n",
    "            model_names['Qwen2.5 72B'].append({i: percentage})\n",
    "        if f\"llama\" in model:\n",
    "            model_names['Llama-4-Mav.'].append({i: percentage})\n",
    "        if f\"gpt\" in model:\n",
    "            model_names['gpt-4o-mini'].append({i: percentage})\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5e87b5-9b32-48e6-b17d-ac59e02b8353",
   "metadata": {},
   "source": [
    "## refuse_swap_mention_participant_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "e1605559-2fbb-4c65-99e9-c8f720438e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_df = df[df['countries'] == curr_countries][refuse_swap_mention_participant_answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "e3162993-39ca-49e3-9a07-c0bc1820d979",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_p_d = {k:[] for k in list(curr_df.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "4da9a952-3ad6-43be-a1d1-fd320e596cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(curr_df)):\n",
    "    for r_n in refuse_swap_mention_participant_answers:\n",
    "        curr_dict = eval(curr_df.iloc[[i]][r_n].values[0])\n",
    "        c_a_a = []\n",
    "        for j in range(len(curr_dict)):\n",
    "            c_p = eval(curr_dict[j])['correct_position']\n",
    "            c_a_a.append(c_p)\n",
    "            \n",
    "        counter = Counter(c_a_a)\n",
    "        most_common = counter.most_common(1)[0][0]\n",
    "        c_p_d[r_n].append(most_common)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d6e7ee83-db44-4195-8b82-1a247c787d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GigaChat-Max_answers_refuse_swap_mention_participant:\n",
      "  Ответ 1: 4 (16.00%)\n",
      "  Ответ 2: 9 (36.00%)\n",
      "  Ответ 3: 3 (12.00%)\n",
      "  Ответ 4: 9 (36.00%)\n",
      "\n",
      "Qwen2.5_72B_answers_refuse_swap_mention_participant:\n",
      "  Ответ 1: 3 (12.00%)\n",
      "  Ответ 2: 9 (36.00%)\n",
      "  Ответ 3: 7 (28.00%)\n",
      "  Ответ 4: 6 (24.00%)\n",
      "\n",
      "llama-4-maverick_answers_refuse_swap_mention_participant:\n",
      "  Ответ 1: 3 (12.00%)\n",
      "  Ответ 2: 3 (12.00%)\n",
      "  Ответ 3: 14 (56.00%)\n",
      "  Ответ 4: 5 (20.00%)\n",
      "\n",
      "gpt-4o-mini_answers_refuse_swap_mention_participant:\n",
      "  Ответ 1: 7 (28.00%)\n",
      "  Ответ 2: 10 (40.00%)\n",
      "  Ответ 3: 8 (32.00%)\n",
      "  Ответ 4: 0 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "for model, responses in c_p_d.items():\n",
    "    counter = Counter(responses)\n",
    "    total_answers = len(refuse_df)\n",
    "    print(f\"\\n{model}:\")\n",
    "    for i in range(1, 5):\n",
    "        count = counter.get(i, 0)\n",
    "        percentage = (count / total_answers) * 100\n",
    "        print(f\"  Ответ {i}: {count} ({percentage:.2f}%)\")\n",
    "\n",
    "        if f\"GigaChat\" in model:\n",
    "            model_names['GigaChat-Max'].append({i: percentage})\n",
    "        if f\"Qwen\" in model:\n",
    "            model_names['Qwen2.5 72B'].append({i: percentage})\n",
    "        if f\"llama\" in model:\n",
    "            model_names['Llama-4-Mav.'].append({i: percentage})\n",
    "        if f\"gpt\" in model:\n",
    "            model_names['gpt-4o-mini'].append({i: percentage})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "30bf844d-0886-4b77-98c2-93be037b6883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GigaChat-Max': [{1: 28.000000000000004}, {2: 56.00000000000001}, {3: 4.0}, {4: 12.0}, {1: 28.000000000000004}, {2: 56.00000000000001}, {3: 8.0}, {4: 8.0}, {1: 12.0}, {2: 28.000000000000004}, {3: 0.0}, {4: 60.0}, {1: 16.0}, {2: 36.0}, {3: 12.0}, {4: 36.0}], 'Qwen2.5 72B': [{1: 32.0}, {2: 40.0}, {3: 4.0}, {4: 24.0}, {1: 32.0}, {2: 36.0}, {3: 4.0}, {4: 28.000000000000004}, {1: 24.0}, {2: 28.000000000000004}, {3: 4.0}, {4: 44.0}, {1: 12.0}, {2: 36.0}, {3: 28.000000000000004}, {4: 24.0}], 'Llama-4-Mav.': [{1: 4.0}, {2: 16.0}, {3: 8.0}, {4: 72.0}, {1: 4.0}, {2: 20.0}, {3: 8.0}, {4: 68.0}, {1: 8.0}, {2: 16.0}, {3: 12.0}, {4: 64.0}, {1: 12.0}, {2: 12.0}, {3: 56.00000000000001}, {4: 20.0}], 'gpt-4o-mini': [{1: 16.0}, {2: 80.0}, {3: 4.0}, {4: 0.0}, {1: 12.0}, {2: 84.0}, {3: 4.0}, {4: 0.0}, {1: 12.0}, {2: 72.0}, {3: 16.0}, {4: 0.0}, {1: 28.000000000000004}, {2: 40.0}, {3: 32.0}, {4: 0.0}]}\n"
     ]
    }
   ],
   "source": [
    "print(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4afa71-3d55-49cf-92c2-5e3786238152",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed17dc01-2be0-4359-912e-8ce8de33e033",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a501fef9-f5b6-411d-bbe7-05efd45eb590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666c50d1-9447-4898-b80f-38f5b2e741f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64aeed5c-74a1-4acc-b05f-0e5b7f62d839",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1d488e-a3b0-49cb-9866-13b2bf4385a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c930fd9-8bc2-4b37-aa2a-1fad9ef8426e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef90e95d-5241-42e7-913b-7bb9cbe68284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117bb7ea-f2c5-428b-b709-b10da5aa6696",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ai_agent]",
   "language": "python",
   "name": "conda-env-ai_agent-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
